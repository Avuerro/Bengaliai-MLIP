{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bengaliai-cv19/test_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_0.parquet\n",
      "/kaggle/input/bengaliai-cv19/train.csv\n",
      "/kaggle/input/bengaliai-cv19/class_map_corrected.csv\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_multi_diacritics.csv\n",
      "/kaggle/input/bengaliai-cv19/class_map.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/test.csv\n",
      "/kaggle/input/bengaliai-cv19/sample_submission.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_0.parquet\n",
      "/kaggle/input/resnet5091acc/acc91_resnet50_saved_weights_1585840262.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# PACKAGES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.models import resnet50,resnet18\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential\n",
    "import time \n",
    "import copy\n",
    "import cv2\n",
    "import imgaug\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = albumentations.augmentations.transforms.Resize(256,256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_char_image(image, threshold=5./255.):\n",
    "    assert image.ndim == 2\n",
    "    is_white = image < threshold\n",
    "    is_black_vertical = np.sum(is_white, axis=0) > 0\n",
    "    is_black_horizontal = np.sum(is_white, axis=1) > 0\n",
    "    left = np.argmax(is_black_horizontal)\n",
    "    right = np.argmax(is_black_horizontal[::-1])\n",
    "    top = np.argmax(is_black_vertical)\n",
    "    bottom = np.argmax(is_black_vertical[::-1])\n",
    "    height, width = image.shape\n",
    "    cropped_image = image[left:height - right, top:width - bottom]\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataloader that combines the images and labels into one convenient class\n",
    "# also uses the make_square function to reshape the images\n",
    "class BengaliDataLoader(Dataset):\n",
    "    def __init__(self,images,labels=None, transform=None, indices=None):\n",
    "        self.images = images.drop('image_id', axis='columns')\n",
    "        self.images = self.images\n",
    "        self.labels = labels\n",
    "        if indices is None:\n",
    "            indices = np.arange(len(self.images))\n",
    "        self.indices = indices\n",
    "        self.train = labels is not None\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "#         idx = self.indices[idx]\n",
    "        img = np.zeros((256, 256, 3))\n",
    "        tmp = self.images.iloc[idx].to_numpy().reshape(137,236)\n",
    "#         tmp = (255 - tmp).astype(np.float32) / 255.\n",
    "        tmp = tmp/255. #tmp.astype(np.float32)/255.\n",
    "\n",
    "        tmp = crop_char_image(tmp,threshold = 250./255.)\n",
    "        tmp = res(image=tmp)['image']\n",
    "        img[..., 0] = tmp\n",
    "        img[..., 1] = img[..., 0]\n",
    "        img[..., 2] = img[..., 0]\n",
    "\n",
    "\n",
    "        x = torch.from_numpy(img)\n",
    "        if self.transform:\n",
    "            x = x.reshape(3,256,256)\n",
    "            x = self.transform(x)\n",
    "\n",
    "#             x = x.reshape(256,256,3)\n",
    "            \n",
    "        if self.train:\n",
    "            y = self.labels[idx]\n",
    "            y = torch.from_numpy(y)\n",
    "            return x,y\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning the network\n",
    "class ResNet50(torch.nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(ResNet50, self).__init__()\n",
    "\n",
    "        self.resnet50 = resnet50(pretrained=False,progress=False)\n",
    "#         for param in self.resnet50.parameters():\n",
    "#             param.requires_grad = False\n",
    "\n",
    "        self.learned_features =  nn.Sequential(*list(self.resnet50.children())[:-1])\n",
    "        \n",
    "        #self.in_features = self.resnet50.fc.in_features\n",
    "\n",
    "#         self.fc0 = nn.Linear(32768,256)\n",
    "        # grapheme_root\n",
    "        self.sm = nn.Softmax(dim=-1)\n",
    "        self.fc1 = nn.Linear(2048,168)\n",
    "        # vowel_diacritic \n",
    "        self.fc2 = nn.Linear(2048,11)\n",
    "        # consonant_diacritic\n",
    "        self.fc3 = nn.Linear(2048,7)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.resnet50(x)\n",
    "        x = self.learned_features(x)\n",
    "#         print(x.shape)\n",
    "#         print(torch.flatten(x,1).shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.shape)\n",
    "#         x = self.fc0(x)\n",
    "        x1 = self.sm(x)\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.sm(x)\n",
    "        x2 = self.fc2(x)\n",
    "        x3 = self.sm(x)\n",
    "        x3 = self.fc3(x)\n",
    "        return x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "composed = transforms.Compose([normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = SeResNext50().to(device)\n",
    "\n",
    "model_ft = ResNet50().to(device)\n",
    "state_dict = torch.load('/kaggle/input/resnet5091acc/acc91_resnet50_saved_weights_1585840262.pth',map_location=torch.device('cpu'))\n",
    "\n",
    "# for key, value in state_dict.items():\n",
    "#     if 'resnet50' in key:\n",
    "#         new_name = 'se_resnext50_32x4d' + key[8:]\n",
    "#         print(key)\n",
    "#         print(new_name)\n",
    "#         print('00000000000000')\n",
    "#         state_dict[new_name] = state_dict.pop(key)\n",
    "# # print(state_dict)\n",
    "model_ft.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.44it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "model_ft.eval()\n",
    "test_data = ['test_image_data_0.parquet','test_image_data_1.parquet','test_image_data_2.parquet','test_image_data_3.parquet']\n",
    "predictions = []\n",
    "for fname in test_data:\n",
    "    test_dataset = BengaliDataLoader(pd.read_parquet(f'/kaggle/input/bengaliai-cv19/{fname}'), transform=composed)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=1,shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs) in tqdm(enumerate(test_dataloader),total=len(test_dataloader)):\n",
    "            inputs = inputs.float().to(device)\n",
    "            outputs = model_ft(inputs)\n",
    "\n",
    "            _, preds_c1 = torch.max(outputs[0], 1)\n",
    "            _, preds_c2 = torch.max(outputs[1], 1)\n",
    "            _, preds_c3 = torch.max(outputs[2], 1)\n",
    "            \n",
    "            predictions.append(preds_c3.cpu().numpy()) # first add consonant\n",
    "            predictions.append(preds_c1.cpu().numpy()) # then grapheme\n",
    "            predictions.append(preds_c2.cpu().numpy()) # then vowel\n",
    "\n",
    "# save results\n",
    "submission = pd.read_csv(f'/kaggle/input/bengaliai-cv19/sample_submission.csv')\n",
    "submission.target = np.hstack(predictions)\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
